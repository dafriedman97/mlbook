Concept
==============

Linear regression can be extended in a number of ways to fit various modeling needs. {doc}`Regularized regression <s1/regularized>` penalizes the magnitude of the regression coefficients to avoid *overfitting*, which is particularly helpful for models using a large number of predictors. {doc}`Bayesian regression <s1/bayesian>` places a prior distribution on the regression coefficients in order to reconcile existing beliefs about these parameters with information gained from new data. Finally, generalized linear models ({doc}`s1/GLMs`) expand on ordinary linear regression by changing the assumed error structure and allowing for the expected value of the target variable to be a nonlinear function of the predictors. These extensions are described, derived, and demonstrated in detail this chapter. 

