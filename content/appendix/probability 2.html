

<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Probability &#8212; Machine Learning from Scratch</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" integrity="sha384-KA6wR/X5RY4zFAHpv/CnoG2UW1uogYfdnP67Uv7eULvTveboZJg0qUpmJZb5VqzN" crossorigin="anonymous">
    <link href="../../_static/css/index.css" rel="stylesheet">
    <link rel="stylesheet" href="../../_static/sphinx-book-theme.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/jupyter-sphinx.css" />
    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/sphinx-book-theme.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/language_data.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/mystnb.js"></script>
    <script src="../../_static/sphinx-book-theme.js"></script>
    <script >var togglebuttonSelector = '.toggle, .secondtoggle, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"TeX": {"Macros": {"sumN": "\\sum_{n = 1}^N", "sumn": "\\sum_{n}", "prodN": "\\prod_{n = 1}^N", "bx": "\\mathbf{x}", "by": "\\mathbf{y}", "bX": "\\mathbf{X}", "bY": "\\mathbf{Y}", "bT": "\\mathbf{T}", "bbeta": "\\boldsymbol{\\beta}", "btheta": "\\boldsymbol{\\hat{\\theta}}}", "bmu": "\\boldsymbol{\\mu}", "bSigma": "\\boldsymbol{\\Sigma}", "bbetahat": "\\boldsymbol{\\hat{\\beta}}", "bbR": "\\mathbb{R}", "iid": "\\overset{\\small{\\text{i.i.d.}}}{\\sim}}", "dadb": ["{\\frac{\\partial #1}{\\partial #2}}", 2], "testing": "\\TeX", "R": "\\mathbb{R}"}}})</script>
    <link rel="shortcut icon" href="../../_static/logo.png"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Common Methods" href="methods.html" />
    <link rel="prev" title="Math" href="math.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="docsearch:language" content="en">



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../index.html">
  
  <img src="../../_static/logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Machine Learning from Scratch</h1>
  
</a>
</div>

<form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  
  <ul class="nav sidenav_l1">
  <li class="">
    <a href="../table_of_contents.html">Table of Contents</a>
  </li>
  <li class="">
    <a href="../conventions_notation.html">Conventions and Notation</a>
  </li>
<li class="navbar-special">
<p class="margin-caption">1. Ordinary Linear Regression</p>
</li>
  <li class="">
    <a href="../c1/concept.html">Concept</a>
  </li>
  <li class="">
    <a href="../c1/construction.html">Construction</a>
  </li>
  <li class="">
    <a href="../c1/code.html">Code</a>
  </li>
<li class="navbar-special">
<p class="margin-caption">2. Linear Regression Extensions</p>
</li>
  <li class="">
    <a href="../c2/concept.html">Concept</a>
  </li>
  <li class="">
    <a href="../c2/construction.html">Construction</a>
  </li>
  <li class="">
    <a href="../c2/code.html">Code</a>
  </li>
<li class="navbar-special">
<p class="margin-caption">3. Discriminative Classifiers (Logistic Regression)</p>
</li>
  <li class="">
    <a href="../c3/concept.html">Concept</a>
  </li>
  <li class="">
    <a href="../c3/construction.html">Construction</a>
  </li>
  <li class="">
    <a href="../c3/code.html">Code</a>
  </li>
<li class="navbar-special">
<p class="margin-caption">4. Generative Classifiers (Naive Bayes)</p>
</li>
  <li class="">
    <a href="../c4/concept.html">Concept</a>
  </li>
  <li class="">
    <a href="../c4/construction.html">Construction</a>
  </li>
  <li class="">
    <a href="../c4/code.html">Code</a>
  </li>
<li class="navbar-special">
<p class="margin-caption">5. Decision Trees</p>
</li>
  <li class="">
    <a href="../c5/concept.html">Concept</a>
  </li>
  <li class="">
    <a href="../c5/construction.html">Construction</a>
  </li>
  <li class="">
    <a href="../c5/code.html">Code</a>
  </li>
<li class="navbar-special">
<p class="margin-caption">6. Tree Ensemble Methods</p>
</li>
  <li class="">
    <a href="../c6/concept.html">Concept</a>
  </li>
  <li class="">
    <a href="../c6/construction.html">Construction</a>
  </li>
  <li class="">
    <a href="../c6/code.html">Code</a>
  </li>
<li class="navbar-special">
<p class="margin-caption">7. Neural Networks</p>
</li>
  <li class="">
    <a href="../c7/concept.html">Concept</a>
  </li>
  <li class="">
    <a href="../c7/construction.html">Construction</a>
  </li>
  <li class="">
    <a href="../c7/code.html">Code</a>
  </li>
<li class="navbar-special">
<p class="margin-caption">Appendix</p>
</li>
  <li class="">
    <a href="math.html">Math</a>
  </li>
  <li class="active">
    <a href="">Probability</a>
  </li>
  <li class="">
    <a href="methods.html">Common Methods</a>
  </li>
  <li class="">
    <a href="data.html">Datasets</a>
  </li>
</ul>
</nav>

 <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse" data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu" aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation" title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        <div class="dropdown-buttons-trigger">
            <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i class="fas fa-download"></i></button>

            
            <div class="dropdown-buttons">
                <!-- ipynb file if we had a myst markdown file -->
                
                <!-- Download raw file -->
                <a class="dropdown-buttons" href="../../_sources/content/appendix/probability.md.txt"><button type="button" class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip" data-placement="left">.md</button></a>
                <!-- Download PDF via print -->
                <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF" onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
            </div>
            
        </div>

        <!-- Edit this page -->
        <a class="edit-button" href="https://github.com/dafriedman97/book/edit/master/content/appendix/probability.md"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="bottom" title="Edit this page"><i class="fas fa-pencil-alt"></i></button></a>

        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="bottom" onclick="toggleFullScreen()" title="Fullscreen mode"><i class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->
        
    </div>
    <div class="d-none d-md-block col-md-2 bd-toc show">
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#random-variables-and-distributions" class="nav-link">1. Random Variables and Distributions</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#random-variables" class="nav-link">Random Variables</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#density-functions" class="nav-link">Density Functions</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#distributions" class="nav-link">Distributions</a>
        </li>
    
            </ul>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#maximum-likelihood-estimation" class="nav-link">2. Maximum Likelihood Estimation</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#conditional-probability" class="nav-link">3. Conditional Probability</a>
        </li>
    
    </ul>
</nav>



<div class="tocsection editthispage">
    <a href="https://github.com/dafriedman97/book/edit/master/content/appendix/probability.md">
        <i class="fas fa-pencil-alt"></i> Edit this page
    </a>
</div>

    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="probability">
<h1>Probability<a class="headerlink" href="#probability" title="Permalink to this headline">¶</a></h1>
<p>Many machine learning methods are rooted in probability theory. Probabilistic methods in this book include <a class="reference internal" href="../c1/concept.html"><span class="doc">linear regression</span></a>, <a class="reference internal" href="../c2/s1/bayesian.html"><span class="doc">Bayesian regression</span></a>, and <a class="reference internal" href="../c4/concept.html"><span class="doc">generative classifiers</span></a>. This section covers the probability theory needed to understand those methods.</p>
<div class="section" id="random-variables-and-distributions">
<h2>1. Random Variables and Distributions<a class="headerlink" href="#random-variables-and-distributions" title="Permalink to this headline">¶</a></h2>
<div class="section" id="random-variables">
<h3>Random Variables<a class="headerlink" href="#random-variables" title="Permalink to this headline">¶</a></h3>
<p>A <strong>random variable</strong> is a variable whose value is randomly determined. The set of possible values a random variable can take on is called the variable’s <strong>support</strong>. An example of a random variable is the value on a die. This variable’s support is <span class="math notranslate nohighlight">\(\{1, 2, 3, 4, 5, 6\}\)</span>. Random variables will be represented with uppercase letters and values in their support with lowercase letters. For instance <span class="math notranslate nohighlight">\(X = x\)</span> implies that a random variable <span class="math notranslate nohighlight">\(X\)</span> happened to take on value <span class="math notranslate nohighlight">\(x\)</span>. Letting <span class="math notranslate nohighlight">\(X\)</span> be the value of a die roll, <span class="math notranslate nohighlight">\(X = 4\)</span> indicates implies that the die landed on 4.</p>
</div>
<div class="section" id="density-functions">
<h3>Density Functions<a class="headerlink" href="#density-functions" title="Permalink to this headline">¶</a></h3>
<p>The likelihood that a random variable takes on a given value is determined through its density function. For a discrete random variable (one that can take on a finite set of values), this density function is called the <strong>probability mass function</strong> <strong>(PMF)</strong>. The PMF of a random variable <span class="math notranslate nohighlight">\(X\)</span> gives the probability <span class="math notranslate nohighlight">\(X\)</span> will equal some value <span class="math notranslate nohighlight">\(x\)</span>. We write it as <span class="math notranslate nohighlight">\(f_X(x)\)</span> or just <span class="math notranslate nohighlight">\(f(x)\)</span>, and it is defined as</p>
<div class="math notranslate nohighlight">
\[
f(x) = P(X = x).
\]</div>
<p>For a continuous random variable (one that can take on infinitely many values), the density function is called the <strong>probability density function (PDF)</strong>. The PDF <span class="math notranslate nohighlight">\(f(x)\)</span> of a continuous random variable <span class="math notranslate nohighlight">\(X\)</span> does not give <span class="math notranslate nohighlight">\(P(X = x)\)</span> but it does determine the probability that <span class="math notranslate nohighlight">\(X\)</span> is in a certain range. Specifically,</p>
<div class="math notranslate nohighlight">
\[
P(a \leq X \leq b) = \int_{x = a}^b f(x) dx. 
\]</div>
<p>That is, integrating <span class="math notranslate nohighlight">\(f(x)\)</span> over a certain range gives the probability of <span class="math notranslate nohighlight">\(X\)</span> being in that range. While <span class="math notranslate nohighlight">\(f(x)\)</span> does not give the probability that <span class="math notranslate nohighlight">\(X\)</span> will equal a certain value, it does indicate the relative likelihood that it will be <em>around</em> that value. E.g. if <span class="math notranslate nohighlight">\(f(a) &gt; f(b)\)</span>, we can say <span class="math notranslate nohighlight">\(X\)</span> is more likely to be in an arbitrarily small area around the value <span class="math notranslate nohighlight">\(a\)</span> than around the value <span class="math notranslate nohighlight">\(b\)</span>.</p>
</div>
<div class="section" id="distributions">
<h3>Distributions<a class="headerlink" href="#distributions" title="Permalink to this headline">¶</a></h3>
<p>A random variable’s <strong>distribution</strong> is determined by its density function. Variables with the same density functions come from the same distributions. Certain families of distributions are very common in probability and machine learning. Two examples are given below.</p>
<p>The <strong>Bernoulli</strong> distribution is the most simple probability distribution and it describes the likelihood of the outcomes of a binary event. Let <span class="math notranslate nohighlight">\(X\)</span> be a random variable that equals 1 (representing “success”) with probability <span class="math notranslate nohighlight">\(p\)</span> and 0 (representing “failure”) with probability <span class="math notranslate nohighlight">\(1-p\)</span>. Then, <span class="math notranslate nohighlight">\(X\)</span> is said to follow the Bernoulli distribution with probability parameter <span class="math notranslate nohighlight">\(p\)</span>, written <span class="math notranslate nohighlight">\(X \sim \text{Bern}(p)\)</span>, and its PMF is given by</p>
<div class="math notranslate nohighlight">
\[
f(x) = p^x(1-p)^{(1-x)}.
\]</div>
<p>We can check to see that for any valid value <span class="math notranslate nohighlight">\(x\)</span> in the support of <span class="math notranslate nohighlight">\(X\)</span>—i.e., 1 or 0—, <span class="math notranslate nohighlight">\(f(x)\)</span> gives <span class="math notranslate nohighlight">\(P(X = x)\)</span>.</p>
<p>The <strong>Normal</strong> distribution is extremely common and will be used throughout this book. A random variable <span class="math notranslate nohighlight">\(X\)</span> follows the Normal distribution with mean parameter <span class="math notranslate nohighlight">\(\mu \in \R\)</span> and variance parameter <span class="math notranslate nohighlight">\(\sigma^2 &gt; 0\)</span>, written <span class="math notranslate nohighlight">\(X \sim \mathcal{N}(\mu, \sigma^2)\)</span>, if its PDF is defined as</p>
<div class="math notranslate nohighlight">
\[
f(x) = \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(x-\mu)^2}{2\sigma^2}}.
\]</div>
<p>The density of a Normal random variable gives this distribution the name “the bell curve”, as shown below. Values closest to <span class="math notranslate nohighlight">\(\mu\)</span> are most likely and the density is symmetric around <span class="math notranslate nohighlight">\(\mu\)</span>.</p>
<p><img alt="normal" src="../../_images/normal.png" /></p>
</div>
</div>
<div class="section" id="maximum-likelihood-estimation">
<h2>2. Maximum Likelihood Estimation<a class="headerlink" href="#maximum-likelihood-estimation" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="conditional-probability">
<h2>3. Conditional Probability<a class="headerlink" href="#conditional-probability" title="Permalink to this headline">¶</a></h2>
</div>
</div>


              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="math.html" title="previous page">Math</a>
    <a class='right-next' id="next-link" href="methods.html" title="next page">Common Methods</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Danny Friedman<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    <script src="../../_static/js/index.js"></script>
    
  </body>
</html>