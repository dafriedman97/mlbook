{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import packages\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "\n",
    "## Load data\n",
    "tips = sns.load_dataset('tips')\n",
    "X = np.array(tips.drop(columns = 'tip'))\n",
    "y = np.array(tips['tip'])\n",
    "\n",
    "## Train-test split\n",
    "np.random.seed(1)\n",
    "test_frac = 0.25\n",
    "test_size = int(len(y)*test_frac)\n",
    "test_idxs = np.random.choice(np.arange(len(y)), test_size, replace = False)\n",
    "X_train = np.delete(X, test_idxs, 0)\n",
    "y_train = np.delete(y, test_idxs, 0)\n",
    "X_test = X[test_idxs]\n",
    "y_test = y[test_idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of their iterative structure, their exhaustive searching, and their non-parametric nature, decision trees are more computationally complex than methods we've seen previously. To clear things up, the construction code is divided into three sections: helper functions, helper classes, and the main decision tree regressor class. \n",
    "\n",
    "We will build our regression tree on the {doc}`tips </content/appendix/data>` dataset from `seaborn`. This dataset has a continuous target variable (tip amount) with both quantitative and categorical predictors. Recall that trees are able to handle categorical predictors without creating one-hot encoded variables, unlike other methods we've seen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are three helper functions we will use in our regression tree. `RSS_reduction()` measures how much a split reduces a parent node's $RSS$ by subtracting the sum of the child $RSS$ values from the parent $RSS$. We will use this to determine the best split for any given bud.\n",
    "\n",
    "The next function, `sort_x_by_y()`, returns a sorted list of the unique categories in some predictor `x` according to the mean of the corresponding target values `y`. We will use this to search for splits on categorical predictors. \n",
    "\n",
    "Finally, `all_rows_equal()` checks if all of a bud's rows (observations) are equal across all predictors. If this is the case, this bud will not be split and instead becomes a terminal leaf. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RSS_reduction(child_L, child_R, parent):\n",
    "    rss_parent = sum((parent - np.mean(parent))**2)\n",
    "    rss_child_L = sum((child_L - np.mean(child_L))**2) \n",
    "    rss_child_R = sum((child_R - np.mean(child_R))**2)\n",
    "    return rss_parent - (rss_child_L + rss_child_R)\n",
    "\n",
    "def sort_x_by_y(x, y):\n",
    "    unique_xs = np.unique(x)\n",
    "    y_mean_by_x = np.array([y[x == unique_x].mean() for unique_x in unique_xs])\n",
    "    ordered_xs = unique_xs[np.argsort(y_mean_by_x)]\n",
    "    return ordered_xs\n",
    "\n",
    "def all_rows_equal(X):\n",
    "    return (X == X[0]).all()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Helper Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are two helpful classes for our main regression tree class. The first, `Node`, represents nodes within our tree. They identify a node's ID and the ID of its parent, its sample of the predictors and the target variable, its size, its depth, and whether or not it is a leaf.\n",
    "\n",
    "The second, `Splitter`, is used to identify the best split of any given bud. It identifies the split's reduction in $RSS$; the variable, `d`, used to make the split; the variable's data type; and the threshold, `t`, (if quantitative) or the set of values, `L_values`, corresponding to the left child node (if categorical). The `Splitter` class fills in these values with its `_replace_split()` method. This method is called if we find a split better than the best split so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \n",
    "    def __init__(self, Xsub, ysub, ID, depth = 0, parent_ID = None, leaf = True):\n",
    "        self.ID = ID\n",
    "        self.Xsub = Xsub\n",
    "        self.ysub = ysub\n",
    "        self.size = len(ysub)\n",
    "        self.depth = depth\n",
    "        self.parent_ID = parent_ID\n",
    "        self.leaf = leaf\n",
    "        \n",
    "class Splitter:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.rss_reduction = 0\n",
    "        self.no_split = True\n",
    "        \n",
    "    def _replace_split(self, rss_reduction, d, dtype = 'quant', t = None, L_values = None):\n",
    "        self.rss_reduction = rss_reduction\n",
    "        self.d = d\n",
    "        self.dtype = dtype\n",
    "        self.t = t        \n",
    "        self.L_values = L_values     \n",
    "        self.no_split = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Main Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to build our main class, the decision tree regressor. The class serves two primary functions: training the model and forming predictions with a trained model. The training is comprised of four methods: `fit()`, `_build()`, `_find_split()`, and `_make_split()`. These methods are covered next.\n",
    "\n",
    "- `fit()`: After instantiating a decision tree object, the user provides training data and calls the `fit()` method. This is the only training method that the user directly calls. The method first records the data and regularization parameters. Then it instantiates a dictionary to store the nodes, called `nodes_dict`, in which nodes are indexed by their IDs. Finally, it calls the `_build()` method to build the tree.\n",
    "\n",
    "\n",
    "- `_build()`: As its name suggests, the `_build()` method actually builds our tree. It relies on the `_find_split()` and `_make_split()` methods discussed next. The method iterates through layers of the tree (starting with just the initial node), splitting each eligible bud before proceeding to the next layer. The eligible buds are tracked by the `eligible_buds` dictionary. A bud is eligible for splitting if it does not already have children (i.e. is a leaf); if it is not smaller than `min_size`, a regularization parameter provided by the user; if its observations are not identical across all predictors; and if it has more than one unique value of the target variable. For each eligible bud, we find a split and make a split, as discussed below. This process continues until there are no eligible buds or we have reached the tree's maximum depth, determined by the argument `max_depth`. \n",
    "\n",
    "\n",
    "- `_find_split()`: When looping through eligible buds in the `_build()` method, we determine their splits with the `_find_split()` method. This method instantaites an object of the `Splitter` class described above. It then loops through all predictors and all possible splits of that predictor to determine which split most reduces the bud's $RSS$. If the predictor is quantitative, we loop through each unique value and calculate the $RSS$ reduction from splitting at that threshold. If the predictor is categorical, we first call `sort_x_by_y()` to order the categories of `x`, and then calculate the $RSS$ reduction for the following splits, where the ordered categories are given by $c_1, \\dots, c_V$.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\{c_1\\} &\\text{ vs. } \\{c_2, \\dots, c_V\\}\\\\\n",
    "\\{c_1, c_2\\} &\\text{ vs. } \\{c_3, \\dots, c_V\\}\\\\\n",
    "& \\dots \\\\\n",
    "\\{c_1, \\dots c_{V-1} \\} &\\text{ vs. } \\{c_V\\}.\\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "\n",
    "- `_make_split()`: Once identified, splits are actually conducted with the `_make_split()` method. This method updates the parent node with the split information and creates the two child nodes. For the parent node, we record which predictor was used to make the split and how. We also add the IDs of the child nodes. For each child node, we record the training observations passing through the node, its ID, its parent's ID, and its size and depth\n",
    "\n",
    "\n",
    "Finally, we use our built tree to form predictions. This is a two step process. First, we use the `_get_leaf_means()` method to calculate the average of the target variable among training observations landing in each leaf. Then we use `predict()` to run each test observation through the tree and return a fitted value: the mean target variable in the corresponding leaf. Note that the user only directly calls `predict()`, which itself calls `_get_leaf_means()`. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{note}\n",
    "Note that the `_fit()` and `_find_split()` methods refer to an argument `C`. This parameter is used by random forests, which are discussed in chapter 6. This argument can be ignored for the purposes of building a decision tree.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeRegressor:\n",
    "    \n",
    "    #############################\n",
    "    ######## 1. TRAINING ########\n",
    "    #############################\n",
    "    \n",
    "    ######### FIT ##########\n",
    "    def fit(self, X, y, max_depth = 100, min_size = 2, C = None):\n",
    "        \n",
    "        ## Add data\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.N, self.D = self.X.shape\n",
    "        dtypes = [np.array(list(self.X[:,d])).dtype for d in range(self.D)]\n",
    "        self.dtypes = ['quant' if (dtype == float or dtype == int) else 'cat' for dtype in dtypes]\n",
    "        \n",
    "        ## Add regularization parameters\n",
    "        self.max_depth = max_depth\n",
    "        self.min_size = min_size\n",
    "        self.C = C\n",
    "        \n",
    "        ## Initialize nodes\n",
    "        self.nodes_dict = {}\n",
    "        self.current_ID = 0\n",
    "        initial_node = Node(Xsub = X, ysub = y, ID = self.current_ID, parent_ID = None)\n",
    "        self.nodes_dict[self.current_ID] = initial_node\n",
    "        self.current_ID += 1\n",
    "        \n",
    "        ## Build\n",
    "        self._build()\n",
    "        \n",
    "    ###### BUILD TREE ######\n",
    "    def _build(self):\n",
    "        \n",
    "        eligible_buds = self.nodes_dict \n",
    "        for layer in range(self.max_depth):\n",
    "            \n",
    "            ## Find eligible nodes for layer iteration\n",
    "            eligible_buds = {ID:node for (ID, node) in self.nodes_dict.items() if \n",
    "                                (node.leaf == True) &\n",
    "                                (node.size >= self.min_size) & \n",
    "                                (~all_rows_equal(node.Xsub)) &\n",
    "                                (len(np.unique(node.ysub)) > 1)}\n",
    "            if len(eligible_buds) == 0:\n",
    "                break\n",
    "                \n",
    "            ## split each eligible parent\n",
    "            for ID, bud in eligible_buds.items():\n",
    "                                \n",
    "                ## Find split\n",
    "                self._find_split(bud)\n",
    "                \n",
    "                ## Make split\n",
    "                if not self.splitter.no_split: # could be no split for Random Forest\n",
    "                    self._make_split()\n",
    "        \n",
    "    \n",
    "    ###### FIND SPLIT ######\n",
    "    def _find_split(self, bud):\n",
    "        \n",
    "        ## Instantiate splitter\n",
    "        splitter = Splitter()\n",
    "        splitter.bud_ID = bud.ID\n",
    "        \n",
    "        ## Gather eligible predictors (for Random Forests)\n",
    "        if self.C is None:\n",
    "            eligible_predictors = np.arange(self.D)\n",
    "        else:\n",
    "            eligible_predictors = np.random.choice(np.arange(self.D), self.C, replace = False)\n",
    "        \n",
    "        ## For each (eligible) predictor...\n",
    "        for d in sorted(eligible_predictors):\n",
    "            Xsub_d = bud.Xsub[:,d]\n",
    "            dtype = self.dtypes[d]\n",
    "            if len(np.unique(Xsub_d)) == 1:\n",
    "                continue\n",
    "\n",
    "            ## For each threshold value...\n",
    "            if dtype == 'quant':\n",
    "                for t in np.unique(Xsub_d)[:-1]:\n",
    "                    ysub_L = bud.ysub[Xsub_d <= t]\n",
    "                    ysub_R = bud.ysub[Xsub_d > t]\n",
    "                    rss_reduction = RSS_reduction(ysub_L, ysub_R, bud.ysub)\n",
    "                    if rss_reduction > splitter.rss_reduction:\n",
    "                        splitter._replace_split(rss_reduction, d, dtype = 'quant', t = t)\n",
    "            else:\n",
    "                ordered_x = sort_x_by_y(Xsub_d, bud.ysub)\n",
    "                for i in range(len(ordered_x) - 1):\n",
    "                    L_values = ordered_x[:i+1]\n",
    "                    ysub_L = bud.ysub[np.isin(Xsub_d, L_values)]\n",
    "                    ysub_R = bud.ysub[~np.isin(Xsub_d, L_values)]\n",
    "                    rss_reduction = RSS_reduction(ysub_L, ysub_R, bud.ysub)\n",
    "                    if rss_reduction > splitter.rss_reduction: \n",
    "                        splitter._replace_split(rss_reduction, d, dtype = 'cat', L_values = L_values)\n",
    "        \n",
    "        ## Save splitter\n",
    "        self.splitter = splitter\n",
    "        \n",
    "    ###### MAKE SPLIT ######\n",
    "    def _make_split(self):\n",
    "        ## Update parent node\n",
    "        parent_node = self.nodes_dict[self.splitter.bud_ID]\n",
    "        parent_node.leaf = False\n",
    "        parent_node.child_L = self.current_ID\n",
    "        parent_node.child_R = self.current_ID + 1\n",
    "        parent_node.d = self.splitter.d\n",
    "        parent_node.dtype = self.splitter.dtype\n",
    "        parent_node.t = self.splitter.t        \n",
    "        parent_node.L_values = self.splitter.L_values\n",
    "        \n",
    "        ## Get X and y data for children\n",
    "        if parent_node.dtype == 'quant':\n",
    "            L_condition = parent_node.Xsub[:,parent_node.d] <= parent_node.t\n",
    "     \n",
    "        else:\n",
    "            L_condition = np.isin(parent_node.Xsub[:,parent_node.d], parent_node.L_values)\n",
    "        Xchild_L = parent_node.Xsub[L_condition]\n",
    "        ychild_L = parent_node.ysub[L_condition]\n",
    "        Xchild_R = parent_node.Xsub[~L_condition]\n",
    "        ychild_R = parent_node.ysub[~L_condition]\n",
    "\n",
    "        \n",
    "        ## Create child nodes\n",
    "        child_node_L = Node(Xchild_L, ychild_L, depth = parent_node.depth + 1,\n",
    "                            ID = self.current_ID, parent_ID = parent_node.ID)\n",
    "        child_node_R = Node(Xchild_R, ychild_R, depth = parent_node.depth + 1,\n",
    "                            ID = self.current_ID+1, parent_ID = parent_node.ID)\n",
    "        self.nodes_dict[self.current_ID] = child_node_L\n",
    "        self.nodes_dict[self.current_ID + 1] = child_node_R\n",
    "        self.current_ID += 2\n",
    "    \n",
    "                \n",
    "            \n",
    "    #############################\n",
    "    ####### 2. PREDICTING #######\n",
    "    #############################\n",
    "    \n",
    "    ###### LEAF MEANS ######\n",
    "    def _get_leaf_means(self):\n",
    "        self.leaf_means = {}\n",
    "        for node_ID, node in self.nodes_dict.items():\n",
    "            if node.leaf:\n",
    "                self.leaf_means[node_ID] = node.ysub.mean()\n",
    "\n",
    "                \n",
    "    ####### PREDICT ########\n",
    "    def predict(self, X_test):\n",
    "        \n",
    "        ## Calculate leaf means\n",
    "        self._get_leaf_means()\n",
    "     \n",
    "        yhat = []\n",
    "        for x in X_test:\n",
    "            node = self.nodes_dict[0] \n",
    "            while not node.leaf:\n",
    "                if node.dtype == 'quant':\n",
    "                    if x[node.d] <= node.t:\n",
    "                        node = self.nodes_dict[node.child_L]\n",
    "                    else:\n",
    "                        node = self.nodes_dict[node.child_R]\n",
    "                else:\n",
    "                    if x[node.d] in node.L_values:\n",
    "                        node = self.nodes_dict[node.child_L]\n",
    "                    else:\n",
    "                        node = self.nodes_dict[node.child_R]\n",
    "            yhat.append(self.leaf_means[node.ID])\n",
    "        return np.array(yhat)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A regression tree is built below on the `tips` dataset. We also plot the target variable from the test observations against their fitted values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Build model\n",
    "tree = DecisionTreeRegressor()\n",
    "tree.fit(X_train, y_train, max_depth = 7, min_size = 5)\n",
    "y_test_hat = tree.predict(X_test)\n",
    "\n",
    "## Visualize predictions\n",
    "if __name__ == '__main__':\n",
    "    fig, ax = plt.subplots(figsize = (7, 5))\n",
    "    sns.scatterplot(y_test, tree.predict(X_test))\n",
    "    ax.set(xlabel = r'$y$', ylabel = r'$\\hat{y}$', title = r'Test Sample $y$ vs. $\\hat{y}$')\n",
    "    sns.despine()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
